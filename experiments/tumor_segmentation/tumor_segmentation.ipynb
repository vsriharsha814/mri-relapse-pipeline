{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0019873c-12fb-43ad-948a-1c88dc8205c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 57195\n",
      "Train files: 45756\n",
      "Val files: 11439\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def data_generator(file_list, batch_size=4):\n",
    "    \"\"\"\n",
    "    Generator that loads and yields batches on-the-fly\n",
    "    Avoids loading all data into RAM\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Shuffle files each epoch\n",
    "        np.random.shuffle(file_list)\n",
    "        \n",
    "        for i in range(0, len(file_list), batch_size):\n",
    "            batch_files = file_list[i:i+batch_size]\n",
    "            images = []\n",
    "            masks = []\n",
    "            \n",
    "            for file_path in batch_files:\n",
    "                try:\n",
    "                    with h5py.File(file_path, 'r') as f:\n",
    "                        image = f['image'][:]\n",
    "                        mask = f['mask'][:]\n",
    "                        \n",
    "                        # Only keep slices with substantial tumor\n",
    "                        if np.sum(mask > 0) > 100:\n",
    "                            # Normalize per-slice\n",
    "                            image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "                            mask = (mask > 0).astype(np.float32)\n",
    "                            \n",
    "                            images.append(image)\n",
    "                            masks.append(mask)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Only yield if we have data\n",
    "            if len(images) > 0:\n",
    "                yield np.array(images), np.array(masks)\n",
    "\n",
    "# Get all files\n",
    "data_dir = './data/BraTS/BraTS2020_training_data/content/data'\n",
    "all_files = glob.glob(f'{data_dir}/*.h5')\n",
    "print(f\"Total files found: {len(all_files)}\")\n",
    "\n",
    "# Shuffle and split 80/20\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_files)\n",
    "split_idx = int(0.8 * len(all_files))\n",
    "\n",
    "train_files = all_files[:split_idx]\n",
    "val_files = all_files[split_idx:]\n",
    "\n",
    "print(f\"Train files: {len(train_files)}\")\n",
    "print(f\"Val files: {len(val_files)}\")\n",
    "\n",
    "# Create generators\n",
    "train_gen = data_generator(train_files, batch_size=4)\n",
    "val_gen = data_generator(val_files, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b223a-f5ea-485b-999b-d96d283dec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - dice_coef: 0.5520 - loss: 0.4573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3647s\u001b[0m 319ms/step - dice_coef: 0.6364 - loss: 0.3687 - val_dice_coef: 0.7051 - val_loss: 0.2978 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - dice_coef: 0.7063 - loss: 0.2965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2864s\u001b[0m 250ms/step - dice_coef: 0.7161 - loss: 0.2861 - val_dice_coef: 0.7197 - val_loss: 0.2810 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - dice_coef: 0.7418 - loss: 0.2598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2957s\u001b[0m 259ms/step - dice_coef: 0.7435 - loss: 0.2579 - val_dice_coef: 0.7611 - val_loss: 0.2382 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - dice_coef: 0.7559 - loss: 0.2458"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3571s\u001b[0m 312ms/step - dice_coef: 0.7598 - loss: 0.2417 - val_dice_coef: 0.7629 - val_loss: 0.2350 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - dice_coef: 0.7710 - loss: 0.2319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2923s\u001b[0m 255ms/step - dice_coef: 0.7723 - loss: 0.2295 - val_dice_coef: 0.7839 - val_loss: 0.2145 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3026s\u001b[0m 265ms/step - dice_coef: 0.7797 - loss: 0.2191 - val_dice_coef: 0.7816 - val_loss: 0.2219 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - dice_coef: 0.7864 - loss: 0.2130"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2953s\u001b[0m 258ms/step - dice_coef: 0.7913 - loss: 0.2084 - val_dice_coef: 0.8060 - val_loss: 0.1947 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3042s\u001b[0m 266ms/step - dice_coef: 0.7965 - loss: 0.2029 - val_dice_coef: 0.8031 - val_loss: 0.1969 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - dice_coef: 0.8014 - loss: 0.1979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3003s\u001b[0m 263ms/step - dice_coef: 0.8040 - loss: 0.1953 - val_dice_coef: 0.8068 - val_loss: 0.1913 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - dice_coef: 0.8056 - loss: 0.1944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2953s\u001b[0m 258ms/step - dice_coef: 0.8089 - loss: 0.1908 - val_dice_coef: 0.8152 - val_loss: 0.1852 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2801s\u001b[0m 245ms/step - dice_coef: 0.8174 - loss: 0.1828 - val_dice_coef: 0.8124 - val_loss: 0.1862 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - dice_coef: 0.8216 - loss: 0.1784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2803s\u001b[0m 245ms/step - dice_coef: 0.8212 - loss: 0.1782 - val_dice_coef: 0.8211 - val_loss: 0.1781 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - dice_coef: 0.8262 - loss: 0.1742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6624s\u001b[0m 579ms/step - dice_coef: 0.8249 - loss: 0.1754 - val_dice_coef: 0.8274 - val_loss: 0.1723 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2937s\u001b[0m 257ms/step - dice_coef: 0.8290 - loss: 0.1710 - val_dice_coef: 0.8248 - val_loss: 0.1739 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - dice_coef: 0.8320 - loss: 0.1671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2825s\u001b[0m 247ms/step - dice_coef: 0.8342 - loss: 0.1659 - val_dice_coef: 0.8346 - val_loss: 0.1650 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2805s\u001b[0m 245ms/step - dice_coef: 0.8363 - loss: 0.1637 - val_dice_coef: 0.8282 - val_loss: 0.1702 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2808s\u001b[0m 245ms/step - dice_coef: 0.8384 - loss: 0.1613 - val_dice_coef: 0.8305 - val_loss: 0.1681 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2795s\u001b[0m 244ms/step - dice_coef: 0.8425 - loss: 0.1576 - val_dice_coef: 0.8341 - val_loss: 0.1643 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - dice_coef: 0.8440 - loss: 0.1557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2808s\u001b[0m 245ms/step - dice_coef: 0.8447 - loss: 0.1556 - val_dice_coef: 0.8421 - val_loss: 0.1578 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2820s\u001b[0m 247ms/step - dice_coef: 0.8480 - loss: 0.1521 - val_dice_coef: 0.8406 - val_loss: 0.1592 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2796s\u001b[0m 244ms/step - dice_coef: 0.8492 - loss: 0.1511 - val_dice_coef: 0.8406 - val_loss: 0.1563 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2821s\u001b[0m 247ms/step - dice_coef: 0.8511 - loss: 0.1487 - val_dice_coef: 0.8396 - val_loss: 0.1604 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - dice_coef: 0.8532 - loss: 0.1468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2835s\u001b[0m 248ms/step - dice_coef: 0.8540 - loss: 0.1463 - val_dice_coef: 0.8483 - val_loss: 0.1513 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2802s\u001b[0m 245ms/step - dice_coef: 0.8566 - loss: 0.1437 - val_dice_coef: 0.8479 - val_loss: 0.1516 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2805s\u001b[0m 245ms/step - dice_coef: 0.8572 - loss: 0.1429 - val_dice_coef: 0.8424 - val_loss: 0.1552 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - dice_coef: 0.8580 - loss: 0.1424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2814s\u001b[0m 246ms/step - dice_coef: 0.8588 - loss: 0.1413 - val_dice_coef: 0.8554 - val_loss: 0.1460 - learning_rate: 1.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2788s\u001b[0m 244ms/step - dice_coef: 0.8611 - loss: 0.1390 - val_dice_coef: 0.8473 - val_loss: 0.1521 - learning_rate: 1.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2739s\u001b[0m 239ms/step - dice_coef: 0.8629 - loss: 0.1378 - val_dice_coef: 0.8512 - val_loss: 0.1478 - learning_rate: 1.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2738s\u001b[0m 239ms/step - dice_coef: 0.8637 - loss: 0.1370 - val_dice_coef: 0.8541 - val_loss: 0.1444 - learning_rate: 1.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - dice_coef: 0.8661 - loss: 0.1351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2814s\u001b[0m 246ms/step - dice_coef: 0.8651 - loss: 0.1355 - val_dice_coef: 0.8582 - val_loss: 0.1404 - learning_rate: 1.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2808s\u001b[0m 245ms/step - dice_coef: 0.8658 - loss: 0.1345 - val_dice_coef: 0.8573 - val_loss: 0.1432 - learning_rate: 1.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2844s\u001b[0m 249ms/step - dice_coef: 0.8678 - loss: 0.1330 - val_dice_coef: 0.8563 - val_loss: 0.1433 - learning_rate: 1.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - dice_coef: 0.8702 - loss: 0.1308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2841s\u001b[0m 248ms/step - dice_coef: 0.8690 - loss: 0.1319 - val_dice_coef: 0.8598 - val_loss: 0.1402 - learning_rate: 1.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9088s\u001b[0m 794ms/step - dice_coef: 0.8707 - loss: 0.1297 - val_dice_coef: 0.8556 - val_loss: 0.1425 - learning_rate: 1.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - dice_coef: 0.8681 - loss: 0.1319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2921s\u001b[0m 255ms/step - dice_coef: 0.8691 - loss: 0.1310 - val_dice_coef: 0.8602 - val_loss: 0.1388 - learning_rate: 1.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3001s\u001b[0m 262ms/step - dice_coef: 0.8711 - loss: 0.1292 - val_dice_coef: 0.8596 - val_loss: 0.1425 - learning_rate: 1.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - dice_coef: 0.8730 - loss: 0.1276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2891s\u001b[0m 253ms/step - dice_coef: 0.8730 - loss: 0.1276 - val_dice_coef: 0.8605 - val_loss: 0.1381 - learning_rate: 1.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - dice_coef: 0.8736 - loss: 0.1274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2860s\u001b[0m 250ms/step - dice_coef: 0.8742 - loss: 0.1268 - val_dice_coef: 0.8635 - val_loss: 0.1365 - learning_rate: 1.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - dice_coef: 0.8756 - loss: 0.1257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2848s\u001b[0m 249ms/step - dice_coef: 0.8756 - loss: 0.1254 - val_dice_coef: 0.8653 - val_loss: 0.1344 - learning_rate: 1.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - dice_coef: 0.8750 - loss: 0.1260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2847s\u001b[0m 249ms/step - dice_coef: 0.8757 - loss: 0.1252 - val_dice_coef: 0.8658 - val_loss: 0.1345 - learning_rate: 1.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - dice_coef: 0.8769 - loss: 0.1241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2843s\u001b[0m 249ms/step - dice_coef: 0.8762 - loss: 0.1246 - val_dice_coef: 0.8667 - val_loss: 0.1336 - learning_rate: 1.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2807s\u001b[0m 245ms/step - dice_coef: 0.8758 - loss: 0.1246 - val_dice_coef: 0.8652 - val_loss: 0.1343 - learning_rate: 1.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2940s\u001b[0m 257ms/step - dice_coef: 0.8785 - loss: 0.1223 - val_dice_coef: 0.8551 - val_loss: 0.1447 - learning_rate: 1.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - dice_coef: 0.8800 - loss: 0.1215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11439/11439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2909s\u001b[0m 254ms/step - dice_coef: 0.8792 - loss: 0.1219 - val_dice_coef: 0.8694 - val_loss: 0.1306 - learning_rate: 1.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m  101/11439\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:17\u001b[0m 229ms/step - dice_coef: 0.8859 - loss: 0.1171"
     ]
    }
   ],
   "source": [
    "# 1. Set seeds\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# 2. Build model\n",
    "def build_unet(input_shape=(240, 240, 4)):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "    c1 = layers.Dropout(0.1)(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "    c2 = layers.Dropout(0.1)(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "    c3 = layers.Dropout(0.2)(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = layers.UpSampling2D((2, 2))(c3)\n",
    "    u4 = layers.concatenate([u4, c2])\n",
    "    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u4)\n",
    "    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n",
    "    c4 = layers.Dropout(0.1)(c4)\n",
    "    \n",
    "    u5 = layers.UpSampling2D((2, 2))(c4)\n",
    "    u5 = layers.concatenate([u5, c1])\n",
    "    c5 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = layers.Dropout(0.1)(c5)\n",
    "    \n",
    "    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(c5)\n",
    "    \n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "model = build_unet()\n",
    "\n",
    "# 3. Define losses\n",
    "def dice_coef(y_true, y_pred, smooth=1e-5):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    bce = -(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "    p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "    focal_weight = alpha * tf.pow(1 - p_t, gamma)\n",
    "    return tf.reduce_mean(focal_weight * bce)\n",
    "\n",
    "def combined_focal_dice(y_true, y_pred):\n",
    "    return focal_loss(y_true, y_pred, alpha=0.25, gamma=0.2) + dice_loss(y_true, y_pred)\n",
    "\n",
    "# 4. Compile\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=combined_focal_dice,\n",
    "    metrics=[dice_coef]\n",
    ")\n",
    "\n",
    "# 5. Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_dice_coef', patience=20, mode='max', restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=5, mode='max', verbose=1),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_dice_coef', mode='max', save_best_only=True)\n",
    "]\n",
    "\n",
    "# 6. Train with generators\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_files) // 4,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(val_files) // 4,\n",
    "    epochs=150,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8ef33-844c-4651-be67-3144706c42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['dice_coef'], label='Train Dice')\n",
    "plt.plot(history.history['val_dice_coef'], label='Val Dice')\n",
    "plt.legend()\n",
    "plt.title('Dice Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185851c-77e0-4f99-b0d7-c10a9f07749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i, 0].imshow(X_val[i, :, :, 0], cmap='gray')\n",
    "    axes[i, 0].set_title('MRI Input')\n",
    "    \n",
    "    axes[i, 1].imshow(y_val[i, :, :, 0], cmap='Reds')\n",
    "    axes[i, 1].set_title('Ground Truth')\n",
    "    \n",
    "    axes[i, 2].imshow(predictions[i, :, :, 0] > 0.5, cmap='Reds')\n",
    "    axes[i, 2].set_title('Prediction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe7150-24ae-4afd-b4ca-2948dd29322e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
